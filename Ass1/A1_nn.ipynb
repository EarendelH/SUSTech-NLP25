{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS310 Natural Language Processing\n",
    "\n",
    "### Name: Wang Ziheng\n",
    "### SID: 12310401\n",
    "\n",
    "## Assignment 1. Neural Text Classification\n",
    "\n",
    "**Total points**: 50\n",
    "\n",
    "You should roughtly follow the structure of the notebook. Add additional cells if you feel needed. \n",
    "\n",
    "You can (and you should) re-use the code from Lab 2. \n",
    "\n",
    "Make sure your code is readable and well-structured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_tokenizer(text):\n",
    "    return [char for char in text if '\\u4e00' <= char <= '\\u9fff']\n",
    "\n",
    "def improved_tokenizer(text):\n",
    "    tokens = []\n",
    "    pattern = re.compile(r'[\\u4e00-\\u9fff]+|[a-zA-Z]+|\\d+|[^\\w\\s]')\n",
    "    for match in pattern.finditer(text):\n",
    "        tokens.append(match.group())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumorDataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer):\n",
    "        self.data = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = {}\n",
    "        self.vocab_size = 0\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                item = json.loads(line)\n",
    "                sentence = item['sentence']\n",
    "                tokens = tokenizer(sentence)\n",
    "                label = item['label'][0]\n",
    "                self.data.append((tokens, label))\n",
    "                for token in tokens:\n",
    "                    if token not in self.vocab:\n",
    "                        self.vocab[token] = len(self.vocab)\n",
    "        self.vocab_size = len(self.vocab)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens, label = self.data[idx]\n",
    "        token_ids = [self.vocab[token] for token in tokens]\n",
    "        return token_ids, label\n",
    "def generate_offsets(batch):\n",
    "    offsets = [0]\n",
    "    for tokens in batch:\n",
    "        offsets.append(offsets[-1] + len(tokens))\n",
    "    return offsets[:-1]\n",
    "def collate_fn(batch):\n",
    "    tokens, labels = zip(*batch)\n",
    "    token_ids = [torch.tensor(ids) for ids in tokens]\n",
    "    token_ids = pad_sequence(token_ids, batch_first=True, padding_value=0)  # Padding with 0\n",
    "    token_ids = token_ids.view(-1)\n",
    "    offsets = [0] + [len(ids) for ids in tokens]\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "    return token_ids, offsets, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HumorDataset('/Users/earendelh/Documents/Sophomore_Second/NLP/Ass1/train.jsonl', improved_tokenizer)\n",
    "test_dataset = HumorDataset('/Users/earendelh/Documents/Sophomore_Second/NLP/Ass1/test.jsonl', improved_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumorClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim1, hidden_dim2, output_dim):\n",
    "        super(HumorClassifier, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embed_dim, hidden_dim1),\n",
    "            nn.LayerNorm(hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim2, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = train_dataset.vocab_size\n",
    "embed_dim = 64\n",
    "hidden_dim1 = 128\n",
    "hidden_dim2 = 64\n",
    "output_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HumorClassifier(vocab_size, embed_dim, hidden_dim1, hidden_dim2, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:06,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:01<00:04,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 1.0771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:01<00:03,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.6369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:02<00:02,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.3405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:02<00:02,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.8334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:02<00:01,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.5213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:03<00:01,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.7186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:03<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.5395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:04<00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.8940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.5159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    for token_ids, offsets, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(token_ids, offsets)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7389, Precision: 0.5459, Recall: 0.7389, F1: 0.6279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/NLP/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for token_ids, offsets, labels in test_loader:\n",
    "        outputs = model(token_ids, offsets)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_labels.extend(labels.tolist())\n",
    "        all_preds.extend(predicted.tolist())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Explore Word Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:04,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:01<00:04,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.5828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:01<00:04,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.3643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:02<00:04,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.6817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:03<00:03,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.3535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:04<00:02,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 1.2037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:04<00:02,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.3543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:05<00:01,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.7192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:06<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.6979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 1.1027\n",
      "Jieba Accuracy: 0.7389, Precision: 0.5459, Recall: 0.7389, F1: 0.6279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/miniconda3/envs/NLP/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# use jieba as the tokenizer\n",
    "train_dataset2 = HumorDataset('/Users/earendelh/Documents/Sophomore_Second/NLP/Ass1/train.jsonl', jieba._lcut_for_search)\n",
    "test_dataset2 = HumorDataset('/Users/earendelh/Documents/Sophomore_Second/NLP/Ass1/test.jsonl', jieba._lcut_for_search)\n",
    "train_loader2 = DataLoader(train_dataset2, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader2 = DataLoader(test_dataset2, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "vocab_size = train_dataset2.vocab_size\n",
    "embed_dim = 64\n",
    "hidden_dim1 = 128\n",
    "hidden_dim2 = 64\n",
    "output_dim = 2\n",
    "\n",
    "model2 = HumorClassifier(vocab_size, embed_dim, hidden_dim1, hidden_dim2, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model2.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    model2.train()\n",
    "    for token_ids, offsets, labels in train_loader2:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model2(token_ids, offsets)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "model2.eval()\n",
    "all_labels2 = []\n",
    "all_preds2 = []\n",
    "with torch.no_grad():\n",
    "    for token_ids, offsets, labels in test_loader2:\n",
    "        outputs = model2(token_ids, offsets)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_labels2.extend(labels.tolist())\n",
    "        all_preds2.extend(predicted.tolist())\n",
    "\n",
    "accuracy_jieba = accuracy_score(all_labels2, all_preds2)\n",
    "precision_jieba = precision_score(all_labels2, all_preds2, average='weighted')\n",
    "recall_jieba = recall_score(all_labels2, all_preds2, average='weighted')\n",
    "f1_jieba = f1_score(all_labels2, all_preds2, average='weighted')\n",
    "\n",
    "print(f'Jieba Accuracy: {accuracy_jieba:.4f}, Precision: {precision_jieba:.4f}, Recall: {recall_jieba:.4f}, F1: {f1_jieba:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of the training results\n",
    "\n",
    "I found that the dataset is too small , easily ***overfitting***. Only when I use the very small learning rate and epoch, I can find a different result.\n",
    "\n",
    "From the result below, we can observe that the jieba tokenizer is better than the improved tokenizer and better than basic tokenizer. \n",
    "\n",
    "|Tokenizer|Learning Rate|Epoch|Accuracy| Precision| Recall| F1|\n",
    "|---|---|---|---|---|---|---|\n",
    "|Basic|1e-5|20|0.6482|0.6338|0.6482|0.6404|\n",
    "|Basic|1e-5|10|0.6820|0.6113|0.6820|0.6347|\n",
    "|Basic|1e-3|10|0.7389|0.5459|0.7389|0.6279|\n",
    "|Improved|1e-5|20|0.7097|0.6336|0.7097|0.6493|\n",
    "|Improved|1e-5|10|0.7266|0.6188|0.7266|0.6347|\n",
    "|Improved|1e-3|10|0.7389| 0.5459|0.7389|0.6279|\n",
    "|jieba|1e-5|20|0.7189|0.5849|0.7189|0.6257|\n",
    "|jieba|1e-5|10|0.7389|0.6770|0.7389|0.6307|\n",
    "|jieba|1e-3|10|0.7389|0.5459|0.7389|0.6279|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
