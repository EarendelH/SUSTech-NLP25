使用设备: cuda:3
加载数据完成。输入形状: (1899270, 12), 目标形状: (1899270,)
初始化 wordpos 模型...
使用 WordPOSModel 训练
目标类别分布: [950028      0   8340      4    852   5938      0    105    860     10
   6870  10480  20816    292   1788  82338   7298   7662   2626  24066
   1138    544   9026   7659  90417   3075     23  12584   6604    162
      0    375     23    362  21263     11     66  58560      0    554
     46  13482      2  80077   6184      0  11856      8   5204   7426
   2661     37  82298     69   2580  26750   2420    345   2642      0
  77646   1297   8396  39712      3   6600  24164  39238      0   3342
      6     30      1   3395  16804    851  27289  63590]
开始训练模型...
Epoch 1/10 - Batch 50/1670 - Loss: 4.3365Epoch 1/10 - Batch 100/1670 - Loss: 4.2983Epoch 1/10 - Batch 150/1670 - Loss: 4.2415Epoch 1/10 - Batch 200/1670 - Loss: 4.1928Epoch 1/10 - Batch 250/1670 - Loss: 4.1644Epoch 1/10 - Batch 300/1670 - Loss: 4.1497Epoch 1/10 - Batch 350/1670 - Loss: 4.1143Epoch 1/10 - Batch 400/1670 - Loss: 4.0961Epoch 1/10 - Batch 450/1670 - Loss: 4.1028Epoch 1/10 - Batch 500/1670 - Loss: 4.0794Epoch 1/10 - Batch 550/1670 - Loss: 4.0766Epoch 1/10 - Batch 600/1670 - Loss: 4.0558Epoch 1/10 - Batch 650/1670 - Loss: 4.0379Epoch 1/10 - Batch 700/1670 - Loss: 4.0278Epoch 1/10 - Batch 750/1670 - Loss: 4.0126Epoch 1/10 - Batch 800/1670 - Loss: 3.9991Epoch 1/10 - Batch 850/1670 - Loss: 3.9789Epoch 1/10 - Batch 900/1670 - Loss: 3.9698Epoch 1/10 - Batch 950/1670 - Loss: 3.9633Epoch 1/10 - Batch 1000/1670 - Loss: 3.9469Epoch 1/10 - Batch 1050/1670 - Loss: 3.9428Epoch 1/10 - Batch 1100/1670 - Loss: 3.9429Epoch 1/10 - Batch 1150/1670 - Loss: 3.9347Epoch 1/10 - Batch 1200/1670 - Loss: 3.9235Epoch 1/10 - Batch 1250/1670 - Loss: 3.9206Epoch 1/10 - Batch 1300/1670 - Loss: 3.9139Epoch 1/10 - Batch 1350/1670 - Loss: 3.9053Epoch 1/10 - Batch 1400/1670 - Loss: 3.9041Epoch 1/10 - Batch 1450/1670 - Loss: 3.8979Epoch 1/10 - Batch 1500/1670 - Loss: 3.8910Epoch 1/10 - Batch 1550/1670 - Loss: 3.8807Epoch 1/10 - Batch 1600/1670 - Loss: 3.8734Epoch 1/10 - Batch 1650/1670 - Loss: 3.8699
Epoch 1/10:
训练损失: 3.8668
验证损失: 3.7178, 准确率: 0.0549
耗时: 24.75 秒
Epoch 2/10 - Batch 50/1670 - Loss: 3.6574Epoch 2/10 - Batch 100/1670 - Loss: 3.6964Epoch 2/10 - Batch 150/1670 - Loss: 3.7034Epoch 2/10 - Batch 200/1670 - Loss: 3.7010Epoch 2/10 - Batch 250/1670 - Loss: 3.7137Epoch 2/10 - Batch 300/1670 - Loss: 3.7464Epoch 2/10 - Batch 350/1670 - Loss: 3.7394Epoch 2/10 - Batch 400/1670 - Loss: 3.7345Epoch 2/10 - Batch 450/1670 - Loss: 3.7383Epoch 2/10 - Batch 500/1670 - Loss: 3.7327Epoch 2/10 - Batch 550/1670 - Loss: 3.7139Epoch 2/10 - Batch 600/1670 - Loss: 3.7049Epoch 2/10 - Batch 650/1670 - Loss: 3.6963Epoch 2/10 - Batch 700/1670 - Loss: 3.6968Epoch 2/10 - Batch 750/1670 - Loss: 3.6881Epoch 2/10 - Batch 800/1670 - Loss: 3.6781Epoch 2/10 - Batch 850/1670 - Loss: 3.6605Epoch 2/10 - Batch 900/1670 - Loss: 3.6606Epoch 2/10 - Batch 950/1670 - Loss: 3.6533Epoch 2/10 - Batch 1000/1670 - Loss: 3.6518Epoch 2/10 - Batch 1050/1670 - Loss: 3.6483Epoch 2/10 - Batch 1100/1670 - Loss: 3.6454Epoch 2/10 - Batch 1150/1670 - Loss: 3.6521Epoch 2/10 - Batch 1200/1670 - Loss: 3.6446Epoch 2/10 - Batch 1250/1670 - Loss: 3.6368Epoch 2/10 - Batch 1300/1670 - Loss: 3.6292Epoch 2/10 - Batch 1350/1670 - Loss: 3.6220Epoch 2/10 - Batch 1400/1670 - Loss: 3.6204Epoch 2/10 - Batch 1450/1670 - Loss: 3.6157Epoch 2/10 - Batch 1500/1670 - Loss: 3.6085Epoch 2/10 - Batch 1550/1670 - Loss: 3.6089Epoch 2/10 - Batch 1600/1670 - Loss: 3.6061Epoch 2/10 - Batch 1650/1670 - Loss: 3.5986
Epoch 2/10:
训练损失: 3.5947
验证损失: 3.3699, 准确率: 0.1850
耗时: 23.61 秒
Epoch 3/10 - Batch 50/1670 - Loss: 3.4477Epoch 3/10 - Batch 100/1670 - Loss: 3.3497Epoch 3/10 - Batch 150/1670 - Loss: 3.4103Epoch 3/10 - Batch 200/1670 - Loss: 3.4002Epoch 3/10 - Batch 250/1670 - Loss: 3.3814Epoch 3/10 - Batch 300/1670 - Loss: 3.3897Epoch 3/10 - Batch 350/1670 - Loss: 3.3803Epoch 3/10 - Batch 400/1670 - Loss: 3.3718Epoch 3/10 - Batch 450/1670 - Loss: 3.3684Epoch 3/10 - Batch 500/1670 - Loss: 3.3730Epoch 3/10 - Batch 550/1670 - Loss: 3.3608Epoch 3/10 - Batch 600/1670 - Loss: 3.3696Epoch 3/10 - Batch 650/1670 - Loss: 3.3772Epoch 3/10 - Batch 700/1670 - Loss: 3.3683Epoch 3/10 - Batch 750/1670 - Loss: 3.3558Epoch 3/10 - Batch 800/1670 - Loss: 3.3695Epoch 3/10 - Batch 850/1670 - Loss: 3.3699Epoch 3/10 - Batch 900/1670 - Loss: 3.3587Epoch 3/10 - Batch 950/1670 - Loss: 3.3698Epoch 3/10 - Batch 1000/1670 - Loss: 3.3720Epoch 3/10 - Batch 1050/1670 - Loss: 3.3662Epoch 3/10 - Batch 1100/1670 - Loss: 3.3574Epoch 3/10 - Batch 1150/1670 - Loss: 3.3484Epoch 3/10 - Batch 1200/1670 - Loss: 3.3419Epoch 3/10 - Batch 1250/1670 - Loss: 3.3352Epoch 3/10 - Batch 1300/1670 - Loss: 3.3321Epoch 3/10 - Batch 1350/1670 - Loss: 3.3232Epoch 3/10 - Batch 1400/1670 - Loss: 3.3137Epoch 3/10 - Batch 1450/1670 - Loss: 3.3186Epoch 3/10 - Batch 1500/1670 - Loss: 3.3129Epoch 3/10 - Batch 1550/1670 - Loss: 3.3109Epoch 3/10 - Batch 1600/1670 - Loss: 3.3086Epoch 3/10 - Batch 1650/1670 - Loss: 3.3108
Epoch 3/10:
训练损失: 3.3096
验证损失: 3.1319, 准确率: 0.2206
耗时: 23.67 秒
Epoch 4/10 - Batch 50/1670 - Loss: 3.2339Epoch 4/10 - Batch 100/1670 - Loss: 3.2550Epoch 4/10 - Batch 150/1670 - Loss: 3.2163Epoch 4/10 - Batch 200/1670 - Loss: 3.1986Epoch 4/10 - Batch 250/1670 - Loss: 3.2173Epoch 4/10 - Batch 300/1670 - Loss: 3.2155Epoch 4/10 - Batch 350/1670 - Loss: 3.2121Epoch 4/10 - Batch 400/1670 - Loss: 3.2109Epoch 4/10 - Batch 450/1670 - Loss: 3.1876Epoch 4/10 - Batch 500/1670 - Loss: 3.1989Epoch 4/10 - Batch 550/1670 - Loss: 3.1907Epoch 4/10 - Batch 600/1670 - Loss: 3.1797Epoch 4/10 - Batch 650/1670 - Loss: 3.1835Epoch 4/10 - Batch 700/1670 - Loss: 3.1824Epoch 4/10 - Batch 750/1670 - Loss: 3.1879Epoch 4/10 - Batch 800/1670 - Loss: 3.1799Epoch 4/10 - Batch 850/1670 - Loss: 3.1849Epoch 4/10 - Batch 900/1670 - Loss: 3.1742Epoch 4/10 - Batch 950/1670 - Loss: 3.1760Epoch 4/10 - Batch 1000/1670 - Loss: 3.1723Epoch 4/10 - Batch 1050/1670 - Loss: 3.1658Epoch 4/10 - Batch 1100/1670 - Loss: 3.1661Epoch 4/10 - Batch 1150/1670 - Loss: 3.1609Epoch 4/10 - Batch 1200/1670 - Loss: 3.1601Epoch 4/10 - Batch 1250/1670 - Loss: 3.1608Epoch 4/10 - Batch 1300/1670 - Loss: 3.1642Epoch 4/10 - Batch 1350/1670 - Loss: 3.1581Epoch 4/10 - Batch 1400/1670 - Loss: 3.1672Epoch 4/10 - Batch 1450/1670 - Loss: 3.1622Epoch 4/10 - Batch 1500/1670 - Loss: 3.1556Epoch 4/10 - Batch 1550/1670 - Loss: 3.1555Epoch 4/10 - Batch 1600/1670 - Loss: 3.1565Epoch 4/10 - Batch 1650/1670 - Loss: 3.1521
Epoch 4/10:
训练损失: 3.1578
验证损失: 2.9390, 准确率: 0.1922
耗时: 23.29 秒
Epoch 5/10 - Batch 50/1670 - Loss: 3.0044Epoch 5/10 - Batch 100/1670 - Loss: 2.9539Epoch 5/10 - Batch 150/1670 - Loss: 3.0251Epoch 5/10 - Batch 200/1670 - Loss: 3.0611Epoch 5/10 - Batch 250/1670 - Loss: 3.0705Epoch 5/10 - Batch 300/1670 - Loss: 3.0566Epoch 5/10 - Batch 350/1670 - Loss: 3.0746Epoch 5/10 - Batch 400/1670 - Loss: 3.0784Epoch 5/10 - Batch 450/1670 - Loss: 3.0780Epoch 5/10 - Batch 500/1670 - Loss: 3.0780Epoch 5/10 - Batch 550/1670 - Loss: 3.0750Epoch 5/10 - Batch 600/1670 - Loss: 3.0855Epoch 5/10 - Batch 650/1670 - Loss: 3.0751Epoch 5/10 - Batch 700/1670 - Loss: 3.0760Epoch 5/10 - Batch 750/1670 - Loss: 3.0775Epoch 5/10 - Batch 800/1670 - Loss: 3.0736Epoch 5/10 - Batch 850/1670 - Loss: 3.0792Epoch 5/10 - Batch 900/1670 - Loss: 3.0734Epoch 5/10 - Batch 950/1670 - Loss: 3.0766Epoch 5/10 - Batch 1000/1670 - Loss: 3.0765Epoch 5/10 - Batch 1050/1670 - Loss: 3.0812Epoch 5/10 - Batch 1100/1670 - Loss: 3.0788Epoch 5/10 - Batch 1150/1670 - Loss: 3.0750Epoch 5/10 - Batch 1200/1670 - Loss: 3.0757Epoch 5/10 - Batch 1250/1670 - Loss: 3.0798Epoch 5/10 - Batch 1300/1670 - Loss: 3.0768Epoch 5/10 - Batch 1350/1670 - Loss: 3.0686Epoch 5/10 - Batch 1400/1670 - Loss: 3.0650Epoch 5/10 - Batch 1450/1670 - Loss: 3.0680Epoch 5/10 - Batch 1500/1670 - Loss: 3.0620Epoch 5/10 - Batch 1550/1670 - Loss: 3.0615Epoch 5/10 - Batch 1600/1670 - Loss: 3.0631Epoch 5/10 - Batch 1650/1670 - Loss: 3.0687
Epoch 5/10:
训练损失: 3.0658
验证损失: 2.8825, 准确率: 0.2374
耗时: 23.44 秒
Epoch 6/10 - Batch 50/1670 - Loss: 3.1923Epoch 6/10 - Batch 100/1670 - Loss: 3.1497Epoch 6/10 - Batch 150/1670 - Loss: 3.1110Epoch 6/10 - Batch 200/1670 - Loss: 3.0645Epoch 6/10 - Batch 250/1670 - Loss: 3.0394Epoch 6/10 - Batch 300/1670 - Loss: 3.0403Epoch 6/10 - Batch 350/1670 - Loss: 3.0277Epoch 6/10 - Batch 400/1670 - Loss: 3.0405Epoch 6/10 - Batch 450/1670 - Loss: 3.0443Epoch 6/10 - Batch 500/1670 - Loss: 3.0352Epoch 6/10 - Batch 550/1670 - Loss: 3.0413Epoch 6/10 - Batch 600/1670 - Loss: 3.0359Epoch 6/10 - Batch 650/1670 - Loss: 3.0257Epoch 6/10 - Batch 700/1670 - Loss: 3.0240Epoch 6/10 - Batch 750/1670 - Loss: 3.0171Epoch 6/10 - Batch 800/1670 - Loss: 3.0148Epoch 6/10 - Batch 850/1670 - Loss: 3.0220Epoch 6/10 - Batch 900/1670 - Loss: 3.0247Epoch 6/10 - Batch 950/1670 - Loss: 3.0210Epoch 6/10 - Batch 1000/1670 - Loss: 3.0186Epoch 6/10 - Batch 1050/1670 - Loss: 3.0215Epoch 6/10 - Batch 1100/1670 - Loss: 3.0213Epoch 6/10 - Batch 1150/1670 - Loss: 3.0206Epoch 6/10 - Batch 1200/1670 - Loss: 3.0119Epoch 6/10 - Batch 1250/1670 - Loss: 3.0104Epoch 6/10 - Batch 1300/1670 - Loss: 3.0003Epoch 6/10 - Batch 1350/1670 - Loss: 3.0007Epoch 6/10 - Batch 1400/1670 - Loss: 2.9999Epoch 6/10 - Batch 1450/1670 - Loss: 2.9941Epoch 6/10 - Batch 1500/1670 - Loss: 2.9917Epoch 6/10 - Batch 1550/1670 - Loss: 2.9890Epoch 6/10 - Batch 1600/1670 - Loss: 2.9861Epoch 6/10 - Batch 1650/1670 - Loss: 2.9842
Epoch 6/10:
训练损失: 2.9831
验证损失: 2.8271, 准确率: 0.2042
耗时: 23.51 秒
Epoch 7/10 - Batch 50/1670 - Loss: 2.9584Epoch 7/10 - Batch 100/1670 - Loss: 2.9115Epoch 7/10 - Batch 150/1670 - Loss: 3.0543Epoch 7/10 - Batch 200/1670 - Loss: 3.0422Epoch 7/10 - Batch 250/1670 - Loss: 3.0185Epoch 7/10 - Batch 300/1670 - Loss: 3.0126Epoch 7/10 - Batch 350/1670 - Loss: 2.9965Epoch 7/10 - Batch 400/1670 - Loss: 2.9926Epoch 7/10 - Batch 450/1670 - Loss: 2.9835Epoch 7/10 - Batch 500/1670 - Loss: 2.9777Epoch 7/10 - Batch 550/1670 - Loss: 2.9818Epoch 7/10 - Batch 600/1670 - Loss: 2.9773Epoch 7/10 - Batch 650/1670 - Loss: 2.9903Epoch 7/10 - Batch 700/1670 - Loss: 2.9824Epoch 7/10 - Batch 750/1670 - Loss: 2.9891Epoch 7/10 - Batch 800/1670 - Loss: 2.9803Epoch 7/10 - Batch 850/1670 - Loss: 2.9823Epoch 7/10 - Batch 900/1670 - Loss: 2.9854Epoch 7/10 - Batch 950/1670 - Loss: 2.9841Epoch 7/10 - Batch 1000/1670 - Loss: 2.9859Epoch 7/10 - Batch 1050/1670 - Loss: 2.9769Epoch 7/10 - Batch 1100/1670 - Loss: 2.9761Epoch 7/10 - Batch 1150/1670 - Loss: 2.9816Epoch 7/10 - Batch 1200/1670 - Loss: 2.9763Epoch 7/10 - Batch 1250/1670 - Loss: 2.9708Epoch 7/10 - Batch 1300/1670 - Loss: 2.9675Epoch 7/10 - Batch 1350/1670 - Loss: 2.9674Epoch 7/10 - Batch 1400/1670 - Loss: 2.9623Epoch 7/10 - Batch 1450/1670 - Loss: 2.9659Epoch 7/10 - Batch 1500/1670 - Loss: 2.9656Epoch 7/10 - Batch 1550/1670 - Loss: 2.9701Epoch 7/10 - Batch 1600/1670 - Loss: 2.9682Epoch 7/10 - Batch 1650/1670 - Loss: 2.9645
Epoch 7/10:
训练损失: 2.9621
验证损失: 2.7968, 准确率: 0.1678
耗时: 23.30 秒
Epoch 8/10 - Batch 50/1670 - Loss: 2.8882Epoch 8/10 - Batch 100/1670 - Loss: 2.9542Epoch 8/10 - Batch 150/1670 - Loss: 2.9010Epoch 8/10 - Batch 200/1670 - Loss: 2.9103Epoch 8/10 - Batch 250/1670 - Loss: 2.9215Epoch 8/10 - Batch 300/1670 - Loss: 2.9675Epoch 8/10 - Batch 350/1670 - Loss: 2.9677Epoch 8/10 - Batch 400/1670 - Loss: 2.9729Epoch 8/10 - Batch 450/1670 - Loss: 2.9637Epoch 8/10 - Batch 500/1670 - Loss: 2.9603Epoch 8/10 - Batch 550/1670 - Loss: 2.9513Epoch 8/10 - Batch 600/1670 - Loss: 2.9555Epoch 8/10 - Batch 650/1670 - Loss: 2.9451Epoch 8/10 - Batch 700/1670 - Loss: 2.9510Epoch 8/10 - Batch 750/1670 - Loss: 2.9425Epoch 8/10 - Batch 800/1670 - Loss: 2.9327Epoch 8/10 - Batch 850/1670 - Loss: 2.9255Epoch 8/10 - Batch 900/1670 - Loss: 2.9276Epoch 8/10 - Batch 950/1670 - Loss: 2.9319Epoch 8/10 - Batch 1000/1670 - Loss: 2.9322Epoch 8/10 - Batch 1050/1670 - Loss: 2.9268Epoch 8/10 - Batch 1100/1670 - Loss: 2.9286Epoch 8/10 - Batch 1150/1670 - Loss: 2.9297Epoch 8/10 - Batch 1200/1670 - Loss: 2.9256Epoch 8/10 - Batch 1250/1670 - Loss: 2.9236Epoch 8/10 - Batch 1300/1670 - Loss: 2.9251Epoch 8/10 - Batch 1350/1670 - Loss: 2.9252Epoch 8/10 - Batch 1400/1670 - Loss: 2.9280Epoch 8/10 - Batch 1450/1670 - Loss: 2.9271Epoch 8/10 - Batch 1500/1670 - Loss: 2.9242Epoch 8/10 - Batch 1550/1670 - Loss: 2.9204Epoch 8/10 - Batch 1600/1670 - Loss: 2.9230Epoch 8/10 - Batch 1650/1670 - Loss: 2.9265
Epoch 8/10:
训练损失: 2.9257
验证损失: 2.7103, 准确率: 0.1644
耗时: 22.14 秒
Epoch 9/10 - Batch 50/1670 - Loss: 2.8737Epoch 9/10 - Batch 100/1670 - Loss: 2.8122Epoch 9/10 - Batch 150/1670 - Loss: 2.8475Epoch 9/10 - Batch 200/1670 - Loss: 2.8788Epoch 9/10 - Batch 250/1670 - Loss: 2.8721Epoch 9/10 - Batch 300/1670 - Loss: 2.8642Epoch 9/10 - Batch 350/1670 - Loss: 2.8656Epoch 9/10 - Batch 400/1670 - Loss: 2.8623Epoch 9/10 - Batch 450/1670 - Loss: 2.8629Epoch 9/10 - Batch 500/1670 - Loss: 2.8740Epoch 9/10 - Batch 550/1670 - Loss: 2.8743Epoch 9/10 - Batch 600/1670 - Loss: 2.8778Epoch 9/10 - Batch 650/1670 - Loss: 2.8738Epoch 9/10 - Batch 700/1670 - Loss: 2.8676Epoch 9/10 - Batch 750/1670 - Loss: 2.8690Epoch 9/10 - Batch 800/1670 - Loss: 2.8703Epoch 9/10 - Batch 850/1670 - Loss: 2.8673Epoch 9/10 - Batch 900/1670 - Loss: 2.8688Epoch 9/10 - Batch 950/1670 - Loss: 2.8786Epoch 9/10 - Batch 1000/1670 - Loss: 2.8790Epoch 9/10 - Batch 1050/1670 - Loss: 2.8825Epoch 9/10 - Batch 1100/1670 - Loss: 2.8809Epoch 9/10 - Batch 1150/1670 - Loss: 2.8767Epoch 9/10 - Batch 1200/1670 - Loss: 2.8714Epoch 9/10 - Batch 1250/1670 - Loss: 2.8802Epoch 9/10 - Batch 1300/1670 - Loss: 2.8815Epoch 9/10 - Batch 1350/1670 - Loss: 2.8795Epoch 9/10 - Batch 1400/1670 - Loss: 2.8849Epoch 9/10 - Batch 1450/1670 - Loss: 2.8821Epoch 9/10 - Batch 1500/1670 - Loss: 2.8841Epoch 9/10 - Batch 1550/1670 - Loss: 2.8899Epoch 9/10 - Batch 1600/1670 - Loss: 2.8939Epoch 9/10 - Batch 1650/1670 - Loss: 2.8937
Epoch 9/10:
训练损失: 2.8912
验证损失: 2.7288, 准确率: 0.2870
耗时: 23.46 秒
Epoch 10/10 - Batch 50/1670 - Loss: 2.8175Epoch 10/10 - Batch 100/1670 - Loss: 2.8541Epoch 10/10 - Batch 150/1670 - Loss: 2.8130Epoch 10/10 - Batch 200/1670 - Loss: 2.8281Epoch 10/10 - Batch 250/1670 - Loss: 2.8862Epoch 10/10 - Batch 300/1670 - Loss: 2.8889Epoch 10/10 - Batch 350/1670 - Loss: 2.9026Epoch 10/10 - Batch 400/1670 - Loss: 2.8987Epoch 10/10 - Batch 450/1670 - Loss: 2.8862Epoch 10/10 - Batch 500/1670 - Loss: 2.8761Epoch 10/10 - Batch 550/1670 - Loss: 2.8762Epoch 10/10 - Batch 600/1670 - Loss: 2.8715Epoch 10/10 - Batch 650/1670 - Loss: 2.8697Epoch 10/10 - Batch 700/1670 - Loss: 2.8685Epoch 10/10 - Batch 750/1670 - Loss: 2.8604Epoch 10/10 - Batch 800/1670 - Loss: 2.8552Epoch 10/10 - Batch 850/1670 - Loss: 2.8476Epoch 10/10 - Batch 900/1670 - Loss: 2.8469Epoch 10/10 - Batch 950/1670 - Loss: 2.8505Epoch 10/10 - Batch 1000/1670 - Loss: 2.8514Epoch 10/10 - Batch 1050/1670 - Loss: 2.8554Epoch 10/10 - Batch 1100/1670 - Loss: 2.8533Epoch 10/10 - Batch 1150/1670 - Loss: 2.8549Epoch 10/10 - Batch 1200/1670 - Loss: 2.8504Epoch 10/10 - Batch 1250/1670 - Loss: 2.8474Epoch 10/10 - Batch 1300/1670 - Loss: 2.8512Epoch 10/10 - Batch 1350/1670 - Loss: 2.8545Epoch 10/10 - Batch 1400/1670 - Loss: 2.8602Epoch 10/10 - Batch 1450/1670 - Loss: 2.8569Epoch 10/10 - Batch 1500/1670 - Loss: 2.8569Epoch 10/10 - Batch 1550/1670 - Loss: 2.8523Epoch 10/10 - Batch 1600/1670 - Loss: 2.8533Epoch 10/10 - Batch 1650/1670 - Loss: 2.8523
Epoch 10/10:
训练损失: 2.8528
验证损失: 2.7025, 准确率: 0.1887
耗时: 23.38 秒
保存模型到 results_model/model.pt
