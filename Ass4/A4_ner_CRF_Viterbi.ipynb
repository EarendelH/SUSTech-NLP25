{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS310 Natural Language Processing\n",
    "## Assignment 4. Long Short Term Memory (LSTM) Network for Named Entity Recognition (NER)\n",
    "\n",
    "**Total points**: 50 + (10 bonus)\n",
    "\n",
    "In this assignment, you will implement a Long Short Term Memory (LSTM) network for Named Entity Recognition (NER). \n",
    "\n",
    "Re-use the code in Lab 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from utils import Indexer, read_ner_data_from_connl, get_batch\n",
    "\n",
    "from metrics import MetricsHandler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\" \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "DATA_DIR = '/home/stu_12310401/nlp/SUSTech-NLP25/Ass4/data'\n",
    "GLOVE_PATH = '/home/stu_12310401/nlp/SUSTech-NLP25/Ass4/glove.6B.100d.txt'\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, sentences, tags, word_to_idx, tag_to_idx):\n",
    "        self.sentences = sentences\n",
    "        self.tags = tags\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.tag_to_idx = tag_to_idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        words = self.sentences[idx]\n",
    "        tags = self.tags[idx]\n",
    "        \n",
    "        word_idxs = [self.word_to_idx.get(word.lower(), self.word_to_idx['<UNK>']) for word in words]\n",
    "        tag_idxs = [self.tag_to_idx[tag] for tag in tags]\n",
    "        \n",
    "        return torch.tensor(word_idxs), torch.tensor(tag_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sentences, tags, min_freq=1):\n",
    "    word_counts = Counter()\n",
    "    for sentence in sentences:\n",
    "        word_counts.update([word.lower() for word in sentence])\n",
    "    \n",
    "    word_to_idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "    for word, count in word_counts.items():\n",
    "        if count >= min_freq:\n",
    "            word_to_idx[word] = len(word_to_idx)\n",
    "    \n",
    "    tag_counts = Counter()\n",
    "    for sentence_tags in tags:\n",
    "        tag_counts.update(sentence_tags)\n",
    "    \n",
    "    tag_to_idx = {'<PAD>': 0}\n",
    "    for tag in tag_counts:\n",
    "        tag_to_idx[tag] = len(tag_to_idx)\n",
    "    \n",
    "    return word_to_idx, tag_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(glove_path, word_to_idx, embedding_dim=100):\n",
    "    \"\"\"加载预训练的GloVe词向量\"\"\"\n",
    "    embeddings = np.random.uniform(-0.25, 0.25, (len(word_to_idx), embedding_dim))\n",
    "    embeddings[0] = np.zeros(embedding_dim)\n",
    "    \n",
    "    word_count = 0\n",
    "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, desc=\"加载GloVe词向量\"):\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            if word.lower() in word_to_idx:\n",
    "                vector = np.array(values[1:], dtype='float32')\n",
    "                embeddings[word_to_idx[word.lower()]] = vector\n",
    "                word_count += 1\n",
    "    \n",
    "    print(f\"加载了 {word_count}/{len(word_to_idx)} 个词的预训练词向量\")\n",
    "    return torch.FloatTensor(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    sentences, tags = zip(*batch)\n",
    "    \n",
    "    lengths = [len(s) for s in sentences]\n",
    "    max_len = max(lengths)\n",
    "    \n",
    "    padded_sentences = torch.zeros(len(sentences), max_len).long()\n",
    "    padded_tags = torch.zeros(len(sentences), max_len).long()\n",
    "    \n",
    "    for i, (sentence, tag) in enumerate(zip(sentences, tags)):\n",
    "        end = lengths[i]\n",
    "        padded_sentences[i, :end] = sentence[:end]\n",
    "        padded_tags[i, :end] = tag[:end]\n",
    "    \n",
    "    return padded_sentences, padded_tags, torch.tensor(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "\n",
    "    sentences = []\n",
    "    tags = []\n",
    "    \n",
    "    sentence = []\n",
    "    sentence_tags = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == '' or line.startswith('-DOCSTART-'):\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    tags.append(sentence_tags)\n",
    "                    sentence = []\n",
    "                    sentence_tags = []\n",
    "            else:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:  \n",
    "                    word = parts[0]\n",
    "                    tag = parts[3]\n",
    "                    sentence.append(word)\n",
    "                    sentence_tags.append(tag)\n",
    "    \n",
    "    if sentence:\n",
    "        sentences.append(sentence)\n",
    "        tags.append(sentence_tags)\n",
    "    \n",
    "    return sentences, tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_NER(nn.Module):\n",
    "    def __init__(self, vocab_size, tag_size, embedding_dim, hidden_dim, num_layers, dropout, pretrained_embeddings=None):\n",
    "        super(BiLSTM_NER, self).__init__()\n",
    "        \n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding.weight = nn.Parameter(pretrained_embeddings)\n",
    "        \n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim // 2,  \n",
    "                           num_layers=num_layers, \n",
    "                           bidirectional=True,\n",
    "                           batch_first=True,\n",
    "                           dropout=dropout if num_layers > 1 else 0)\n",
    "        \n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, tag_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        \n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths.cpu(), batch_first=True)\n",
    "        \n",
    "        outputs, _ = self.lstm(packed)\n",
    "        \n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "        \n",
    "        outputs = self.dropout(outputs)\n",
    "        \n",
    "        logits = self.fc(outputs)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BiLSTM_CRF_NER(nn.Module):\n",
    "    def __init__(self, vocab_size, tag_size, embedding_dim, hidden_dim, num_layers, dropout, pretrained_embeddings=None):\n",
    "        super(BiLSTM_CRF_NER, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding.weight = nn.Parameter(pretrained_embeddings)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim // 2,  \n",
    "                           num_layers=num_layers, \n",
    "                           bidirectional=True,\n",
    "                           batch_first=True,\n",
    "                           dropout=dropout if num_layers > 1 else 0)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, tag_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # 添加CRF层\n",
    "        self.transitions = nn.Parameter(torch.randn(tag_size, tag_size))\n",
    "        self.start_transitions = nn.Parameter(torch.randn(tag_size))\n",
    "        self.end_transitions = nn.Parameter(torch.randn(tag_size))\n",
    "        \n",
    "    def _forward_alg(self, emissions, mask):\n",
    "        batch_size, seq_length, tag_size = emissions.size()\n",
    "        \n",
    "        score = self.start_transitions + emissions[:, 0]\n",
    "        \n",
    "        for i in range(1, seq_length):\n",
    "            broadcast_score = score.unsqueeze(2)\n",
    "            broadcast_emissions = emissions[:, i].unsqueeze(1)\n",
    "            \n",
    "            next_score = broadcast_score + self.transitions + broadcast_emissions\n",
    "            \n",
    "            next_score = torch.logsumexp(next_score, dim=1)\n",
    "            \n",
    "            score = torch.where(mask[:, i].unsqueeze(1), next_score, score)\n",
    "        \n",
    "        score = score + self.end_transitions\n",
    "        \n",
    "        return torch.logsumexp(score, dim=1)\n",
    "    \n",
    "    def _score_sentence(self, emissions, tags, mask):\n",
    "\n",
    "        batch_size, seq_length, tag_size = emissions.size()\n",
    "\n",
    "        score = self.start_transitions[tags[:, 0]]\n",
    "        score += emissions[torch.arange(batch_size), 0, tags[:, 0]]\n",
    "        \n",
    "        for i in range(1, seq_length):\n",
    "            valid_scores = emissions[torch.arange(batch_size), i, tags[:, i]]\n",
    "            valid_scores += self.transitions[tags[:, i-1], tags[:, i]]\n",
    "            score += valid_scores * mask[:, i]\n",
    "        \n",
    "        last_tag_indices = mask.sum(1).long() - 1\n",
    "        last_tags = tags[torch.arange(batch_size), last_tag_indices]\n",
    "        score += self.end_transitions[last_tags]\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def _viterbi_decode(self, emissions, mask):\n",
    "        batch_size, seq_length, tag_size = emissions.size()\n",
    "        \n",
    "        score = self.start_transitions + emissions[:, 0]\n",
    "        history = []\n",
    "        \n",
    "        for i in range(1, seq_length):\n",
    "            broadcast_score = score.unsqueeze(2)\n",
    "            broadcast_emission = emissions[:, i].unsqueeze(1)\n",
    "            \n",
    "            next_score = broadcast_score + self.transitions + broadcast_emission\n",
    "            \n",
    "            next_score, indices = next_score.max(dim=1)\n",
    "            \n",
    "            score = torch.where(mask[:, i].unsqueeze(1), next_score, score)\n",
    "            history.append(indices)\n",
    "        \n",
    "        score += self.end_transitions\n",
    "        \n",
    "        best_score, best_tag = score.max(dim=1)\n",
    "        \n",
    "        best_path = torch.zeros(batch_size, seq_length, dtype=torch.long, device=emissions.device)\n",
    "        best_path[:, -1] = best_tag\n",
    "        \n",
    "        for i in range(len(history) - 1, -1, -1):\n",
    "            best_tag = history[i].gather(1, best_tag.unsqueeze(1)).squeeze(1)\n",
    "            best_path[:, i] = best_tag\n",
    "        \n",
    "        return best_path, best_score\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        batch_size, max_len = x.size()\n",
    "        \n",
    "        mask = torch.zeros(batch_size, max_len, dtype=torch.bool, device=x.device)\n",
    "        for i, length in enumerate(lengths):\n",
    "            mask[i, :length] = 1\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        \n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths.cpu(), batch_first=True)\n",
    "        outputs, _ = self.lstm(packed)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "        \n",
    "        outputs = self.dropout(outputs)\n",
    "        emissions = self.fc(outputs)\n",
    "        \n",
    "        return emissions\n",
    "    \n",
    "    def neg_log_likelihood(self, x, lengths, tags):\n",
    "        batch_size, max_len = x.size()\n",
    "        mask = torch.zeros(batch_size, max_len, dtype=torch.bool, device=x.device)\n",
    "        for i, length in enumerate(lengths):\n",
    "            mask[i, :length] = 1\n",
    "        \n",
    "        emissions = self.forward(x, lengths)\n",
    "        \n",
    "        log_Z = self._forward_alg(emissions, mask)\n",
    "        gold_score = self._score_sentence(emissions, tags, mask)\n",
    "        \n",
    "        return log_Z - gold_score\n",
    "    \n",
    "    def decode(self, x, lengths):\n",
    "        batch_size, max_len = x.size()\n",
    "        mask = torch.zeros(batch_size, max_len, dtype=torch.bool, device=x.device)\n",
    "        for i, length in enumerate(lengths):\n",
    "            mask[i, :length] = 1\n",
    "        \n",
    "        emissions = self.forward(x, lengths)\n",
    "        \n",
    "        return self._viterbi_decode(emissions, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for sentences, tags, lengths in tqdm(train_loader, desc=\"Training\"):\n",
    "        sentences = sentences.to(device)\n",
    "        tags = tags.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(sentences, lengths)\n",
    "        \n",
    "        loss = 0\n",
    "        for i in range(logits.size(0)):\n",
    "            loss += criterion(logits[i, :lengths[i]], tags[i, :lengths[i]])\n",
    "        loss /= logits.size(0)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_crf(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for sentences, tags, lengths in tqdm(train_loader, desc=\"Train CRF\"):\n",
    "        sentences = sentences.to(device)\n",
    "        tags = tags.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = model.neg_log_likelihood(sentences, lengths, tags)\n",
    "        loss = loss.mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, tag_to_idx, idx_to_tag, metrics_handler, device):\n",
    "    model.eval()\n",
    "    metrics_handler = MetricsHandler(classes=list(tag_to_idx.keys()))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sentences, tags, lengths in tqdm(data_loader, desc=\"Evaluate \"):\n",
    "            sentences = sentences.to(device)\n",
    "            tags = tags.to(device)\n",
    "\n",
    "            logits = model(sentences, lengths)\n",
    "\n",
    "            for i in range(logits.size(0)):\n",
    "                length = lengths[i]\n",
    "                logits_i = logits[i, :length]\n",
    "                tags_i = tags[i, :length]\n",
    "                \n",
    "                # 贪心\n",
    "                _, predicted = torch.max(logits_i, dim=1)\n",
    "                \n",
    "                pred_tags = [idx_to_tag[idx.item()] for idx in predicted]\n",
    "                true_tags = [idx_to_tag[idx.item()] for idx in tags_i]\n",
    "                \n",
    "                metrics_handler.update(pred_tags, true_tags)\n",
    "    \n",
    "    metrics_handler.collect()\n",
    "    metrics = metrics_handler.get_metrics()\n",
    "    \n",
    "    f1_scores = metrics[\"F1-score\"]\n",
    "    latest_f1 = f1_scores[-1] if f1_scores else 0.0\n",
    "    \n",
    "    return {\"f1\": latest_f1, \"metrics\": metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_crf(model, data_loader, tag_to_idx, idx_to_tag, metrics_handler, device):\n",
    "    model.eval()\n",
    "    metrics_handler = MetricsHandler(classes=list(tag_to_idx.keys()))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sentences, tags, lengths in tqdm(data_loader, desc=\"Evaluate CRF\"):\n",
    "            sentences = sentences.to(device)\n",
    "            tags = tags.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            \n",
    "            # 使用Viterbi解码\n",
    "            best_paths, _ = model.decode(sentences, lengths)\n",
    "            \n",
    "            for i in range(best_paths.size(0)):\n",
    "                length = lengths[i].item()\n",
    "                predicted = best_paths[i, :length]\n",
    "                tags_i = tags[i, :length]\n",
    "                \n",
    "                pred_tags = [idx_to_tag[idx.item()] for idx in predicted]\n",
    "                true_tags = [idx_to_tag[idx.item()] for idx in tags_i]\n",
    "                \n",
    "                metrics_handler.update(pred_tags, true_tags)\n",
    "    \n",
    "    metrics_handler.collect()\n",
    "    metrics = metrics_handler.get_metrics()\n",
    "    \n",
    "    f1_scores = metrics[\"F1-score\"]\n",
    "    latest_f1 = f1_scores[-1] if f1_scores else 0.0\n",
    "    \n",
    "    return {\"f1\": latest_f1, \"metrics\": metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET SIZE: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "加载GloVe词向量: 400000it [00:02, 162196.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载了 18415/21011 个词的预训练词向量\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import get_tag_indices_from_scores\n",
    "from metrics import MetricsHandler\n",
    "\n",
    "labels_str = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\n",
    "labels_int = list(range(len(labels_str)))\n",
    "train_metrics = MetricsHandler(labels_int)\n",
    "\n",
    "train_sentences, train_tags = load_data(os.path.join(DATA_DIR, 'train.txt'))\n",
    "dev_sentences, dev_tags = load_data(os.path.join(DATA_DIR, 'dev.txt'))\n",
    "test_sentences, test_tags = load_data(os.path.join(DATA_DIR, 'test.txt'))\n",
    "\n",
    "word_to_idx, tag_to_idx = build_vocab(train_sentences, train_tags)\n",
    "idx_to_tag = {idx: tag for tag, idx in tag_to_idx.items()}\n",
    "\n",
    "TAGSET_SIZE = len(tag_to_idx)\n",
    "\n",
    "print(f\"TARGET SIZE: {TAGSET_SIZE}\")\n",
    "\n",
    "pretrained_embeddings = load_glove_embeddings(GLOVE_PATH, word_to_idx, EMBEDDING_DIM)\n",
    "\n",
    "train_dataset = NERDataset(train_sentences, train_tags, word_to_idx, tag_to_idx)\n",
    "dev_dataset = NERDataset(dev_sentences, dev_tags, word_to_idx, tag_to_idx)\n",
    "test_dataset = NERDataset(test_sentences, test_tags, word_to_idx, tag_to_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM_NER(\n",
    "    vocab_size=len(word_to_idx),\n",
    "    tag_size=len(tag_to_idx),\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    pretrained_embeddings=pretrained_embeddings\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tag_to_idx['<PAD>'])\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_handler = MetricsHandler(classes=list(range(TAGSET_SIZE)))\n",
    "metrics_handler_crf = MetricsHandler(classes=list(range(TAGSET_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It has model checkpoint, loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_345464/3209027670.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('bilstm_ner_model.pt')\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('bilstm_ner_model.pt'):\n",
    "    print(\"It has model checkpoint, loading...\")\n",
    "    checkpoint = torch.load('bilstm_ner_model.pt')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    word_to_idx = checkpoint['word_to_idx']\n",
    "    tag_to_idx = checkpoint['tag_to_idx']\n",
    "    idx_to_tag = checkpoint['idx_to_tag']\n",
    "else:\n",
    "    print(\"Start_training...\")\n",
    "    train_losses = []\n",
    "    dev_f1_scores = []\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        dev_metrics = evaluate(model, dev_loader, tag_to_idx, idx_to_tag, metrics_handler, device)\n",
    "        dev_f1 = dev_metrics['f1']\n",
    "        dev_f1_scores.append(dev_f1)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {train_loss:.4f}, Dev set F1: {dev_f1:.4f}\")\n",
    "\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'word_to_idx': word_to_idx,\n",
    "        'tag_to_idx': tag_to_idx,\n",
    "        'idx_to_tag': idx_to_tag,\n",
    "        'hyperparams': {\n",
    "            'embedding_dim': EMBEDDING_DIM,\n",
    "            'hidden_dim': HIDDEN_DIM,\n",
    "            'num_layers': NUM_LAYERS,\n",
    "            'dropout': DROPOUT\n",
    "        }\n",
    "    }, 'bilstm_ner_model.pt')\n",
    "    print(\"BiLSTM model trained and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "crf_model = BiLSTM_CRF_NER(\n",
    "    vocab_size=len(word_to_idx),\n",
    "    tag_size=len(tag_to_idx),\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    pretrained_embeddings=pretrained_embeddings\n",
    ").to(device)\n",
    "\n",
    "crf_optimizer = optim.Adam(crf_model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training CRF model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train CRF: 100%|██████████| 110/110 [00:13<00:00,  8.42it/s]\n",
      "Evaluate CRF: 100%|██████████| 26/26 [00:03<00:00,  8.40it/s]\n",
      "/home/stu_12310401/nlp/SUSTech-NLP25/Ass4/metrics.py:5: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return x[1, 1]/(x[1, 1] + x[0, 1])\n",
      "/home/stu_12310401/nlp/SUSTech-NLP25/Ass4/metrics.py:9: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return x[1, 1] / (x[1, 0] + x[1, 1])\n",
      "/home/stu_12310401/nlp/SUSTech-NLP25/Ass4/metrics.py:15: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return ((1 + beta**2)*precision*recall)/(beta**2 * precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 11.5426, Dev set F1: 0.5564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train CRF: 100%|██████████| 110/110 [00:12<00:00,  8.61it/s]\n",
      "Evaluate CRF: 100%|██████████| 26/26 [00:03<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 5.2235, Dev set F1: 0.6394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train CRF: 100%|██████████| 110/110 [00:12<00:00,  8.62it/s]\n",
      "Evaluate CRF: 100%|██████████| 26/26 [00:02<00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 3.4265, Dev set F1: 0.7305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train CRF: 100%|██████████| 110/110 [00:11<00:00,  9.96it/s]\n",
      "Evaluate CRF: 100%|██████████| 26/26 [00:02<00:00, 10.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 2.6634, Dev set F1: 0.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train CRF: 100%|██████████| 110/110 [00:10<00:00, 10.01it/s]\n",
      "Evaluate CRF: 100%|██████████| 26/26 [00:02<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 2.2818, Dev set F1: 0.8028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train CRF: 100%|██████████| 110/110 [00:11<00:00,  9.98it/s]\n",
      "Evaluate CRF: 100%|██████████| 26/26 [00:02<00:00, 11.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 1.9735, Dev set F1: 0.8025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train CRF: 100%|██████████| 110/110 [00:10<00:00, 10.07it/s]\n",
      "Evaluate CRF: 100%|██████████| 26/26 [00:02<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 1.7476, Dev set F1: 0.8202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train CRF: 100%|██████████| 110/110 [00:11<00:00,  9.95it/s]\n",
      "Evaluate CRF: 100%|██████████| 26/26 [00:02<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 1.5591, Dev set F1: 0.8295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train CRF: 100%|██████████| 110/110 [00:10<00:00, 10.05it/s]\n",
      "Evaluate CRF: 100%|██████████| 26/26 [00:02<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 1.4060, Dev set F1: 0.8397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train CRF: 100%|██████████| 110/110 [00:11<00:00, 10.00it/s]\n",
      "Evaluate CRF: 100%|██████████| 26/26 [00:02<00:00, 11.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 1.2792, Dev set F1: 0.8453\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('bilstm_crf_ner_model.pt'):\n",
    "    print(\"It has CRF model checkpoint, loading...\")\n",
    "    checkpoint = torch.load('bilstm_crf_ner_model.pt')\n",
    "    crf_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    word_to_idx = checkpoint['word_to_idx']\n",
    "    tag_to_idx = checkpoint['tag_to_idx']\n",
    "    idx_to_tag = checkpoint['idx_to_tag']\n",
    "else:\n",
    "    print(\"Start training CRF model...\")\n",
    "    crf_train_losses = []\n",
    "    crf_dev_f1_scores = []\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss = train_crf(crf_model, train_loader, crf_optimizer, device)\n",
    "        crf_train_losses.append(train_loss)\n",
    "        \n",
    "        dev_metrics = evaluate_crf(crf_model, dev_loader, tag_to_idx, idx_to_tag, metrics_handler_crf, device)\n",
    "        dev_f1 = dev_metrics['f1']\n",
    "        crf_dev_f1_scores.append(dev_f1)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {train_loss:.4f}, Dev set F1: {dev_f1:.4f}\")\n",
    "\n",
    "    torch.save({\n",
    "        'model_state_dict': crf_model.state_dict(),\n",
    "        'word_to_idx': word_to_idx,\n",
    "        'tag_to_idx': tag_to_idx,\n",
    "        'idx_to_tag': idx_to_tag,\n",
    "        'hyperparams': {\n",
    "            'embedding_dim': EMBEDDING_DIM,\n",
    "            'hidden_dim': HIDDEN_DIM,\n",
    "            'num_layers': NUM_LAYERS,\n",
    "            'dropout': DROPOUT\n",
    "        }\n",
    "    }, 'bilstm_crf_ner_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compare BiLSTM with BILSTM-CRF：\n",
      "--------------------------------------------------------------------------------\n",
      "Model + Decode method          Dev set F1      Test set F1    \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate : 100%|██████████| 26/26 [00:02<00:00, 12.69it/s]\n",
      "Evaluate : 100%|██████████| 27/27 [00:01<00:00, 14.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM + Greedy search         0.8374          0.7860         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate CRF: 100%|██████████| 26/26 [00:02<00:00, 11.11it/s]\n",
      "Evaluate CRF: 100%|██████████| 27/27 [00:02<00:00, 12.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM-CRF + Viterbi           0.8453          0.7927         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\nCompare BiLSTM with BILSTM-CRF：\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Model + Decode method':<30} {'Dev set F1':<15} {'Test set F1':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# BiLSTM + Greedy\n",
    "greedy_dev_metrics = evaluate(model, dev_loader, tag_to_idx, idx_to_tag, metrics_handler, device)\n",
    "greedy_test_metrics = evaluate(model, test_loader, tag_to_idx, idx_to_tag, metrics_handler, device)\n",
    "print(f\"{'BiLSTM + Greedy search':<30} {greedy_dev_metrics['f1']:<15.4f} {greedy_test_metrics['f1']:<15.4f}\")\n",
    "\n",
    "# BiLSTM-CRF + Viterbi\n",
    "crf_dev_metrics = evaluate_crf(crf_model, dev_loader, tag_to_idx, idx_to_tag, metrics_handler, device)\n",
    "crf_test_metrics = evaluate_crf(crf_model, test_loader, tag_to_idx, idx_to_tag, metrics_handler, device)\n",
    "print(f\"{'BiLSTM-CRF + Viterbi':<30} {crf_dev_metrics['f1']:<15.4f} {crf_test_metrics['f1']:<15.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Other Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wzh-py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
