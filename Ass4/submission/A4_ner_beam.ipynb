{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS310 Natural Language Processing\n",
    "## Assignment 4. Long Short Term Memory (LSTM) Network for Named Entity Recognition (NER)\n",
    "\n",
    "**Total points**: 50 + (10 bonus)\n",
    "\n",
    "In this assignment, you will implement a Long Short Term Memory (LSTM) network for Named Entity Recognition (NER). \n",
    "\n",
    "Re-use the code in Lab 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from utils import Indexer, read_ner_data_from_connl, get_batch\n",
    "\n",
    "from metrics import MetricsHandler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\" \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "DATA_DIR = '/home/stu_12310401/nlp/SUSTech-NLP25/Ass4/data'\n",
    "GLOVE_PATH = '/home/stu_12310401/nlp/SUSTech-NLP25/Ass4/glove.6B.100d.txt'\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, sentences, tags, word_to_idx, tag_to_idx):\n",
    "        self.sentences = sentences\n",
    "        self.tags = tags\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.tag_to_idx = tag_to_idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        words = self.sentences[idx]\n",
    "        tags = self.tags[idx]\n",
    "        \n",
    "        word_idxs = [self.word_to_idx.get(word.lower(), self.word_to_idx['<UNK>']) for word in words]\n",
    "        tag_idxs = [self.tag_to_idx[tag] for tag in tags]\n",
    "        \n",
    "        return torch.tensor(word_idxs), torch.tensor(tag_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sentences, tags, min_freq=1):\n",
    "    word_counts = Counter()\n",
    "    for sentence in sentences:\n",
    "        word_counts.update([word.lower() for word in sentence])\n",
    "    \n",
    "    word_to_idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "    for word, count in word_counts.items():\n",
    "        if count >= min_freq:\n",
    "            word_to_idx[word] = len(word_to_idx)\n",
    "    \n",
    "    tag_counts = Counter()\n",
    "    for sentence_tags in tags:\n",
    "        tag_counts.update(sentence_tags)\n",
    "    \n",
    "    tag_to_idx = {'<PAD>': 0}\n",
    "    for tag in tag_counts:\n",
    "        tag_to_idx[tag] = len(tag_to_idx)\n",
    "    \n",
    "    return word_to_idx, tag_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(glove_path, word_to_idx, embedding_dim=100):\n",
    "    \"\"\"加载预训练的GloVe词向量\"\"\"\n",
    "    embeddings = np.random.uniform(-0.25, 0.25, (len(word_to_idx), embedding_dim))\n",
    "    embeddings[0] = np.zeros(embedding_dim)\n",
    "    \n",
    "    word_count = 0\n",
    "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, desc=\"加载GloVe词向量\"):\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            if word.lower() in word_to_idx:\n",
    "                vector = np.array(values[1:], dtype='float32')\n",
    "                embeddings[word_to_idx[word.lower()]] = vector\n",
    "                word_count += 1\n",
    "    \n",
    "    print(f\"加载了 {word_count}/{len(word_to_idx)} 个词的预训练词向量\")\n",
    "    return torch.FloatTensor(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    sentences, tags = zip(*batch)\n",
    "    \n",
    "    lengths = [len(s) for s in sentences]\n",
    "    max_len = max(lengths)\n",
    "    \n",
    "    padded_sentences = torch.zeros(len(sentences), max_len).long()\n",
    "    padded_tags = torch.zeros(len(sentences), max_len).long()\n",
    "    \n",
    "    for i, (sentence, tag) in enumerate(zip(sentences, tags)):\n",
    "        end = lengths[i]\n",
    "        padded_sentences[i, :end] = sentence[:end]\n",
    "        padded_tags[i, :end] = tag[:end]\n",
    "    \n",
    "    return padded_sentences, padded_tags, torch.tensor(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "\n",
    "    sentences = []\n",
    "    tags = []\n",
    "    \n",
    "    sentence = []\n",
    "    sentence_tags = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == '' or line.startswith('-DOCSTART-'):\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    tags.append(sentence_tags)\n",
    "                    sentence = []\n",
    "                    sentence_tags = []\n",
    "            else:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:  \n",
    "                    word = parts[0]\n",
    "                    tag = parts[3]\n",
    "                    sentence.append(word)\n",
    "                    sentence_tags.append(tag)\n",
    "    \n",
    "    if sentence:\n",
    "        sentences.append(sentence)\n",
    "        tags.append(sentence_tags)\n",
    "    \n",
    "    return sentences, tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_NER(nn.Module):\n",
    "    def __init__(self, vocab_size, tag_size, embedding_dim, hidden_dim, num_layers, dropout, pretrained_embeddings=None):\n",
    "        super(BiLSTM_NER, self).__init__()\n",
    "        \n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding.weight = nn.Parameter(pretrained_embeddings)\n",
    "        \n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim // 2,  \n",
    "                           num_layers=num_layers, \n",
    "                           bidirectional=True,\n",
    "                           batch_first=True,\n",
    "                           dropout=dropout if num_layers > 1 else 0)\n",
    "        \n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, tag_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        \n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths.cpu(), batch_first=True)\n",
    "        \n",
    "        outputs, _ = self.lstm(packed)\n",
    "        \n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "        \n",
    "        outputs = self.dropout(outputs)\n",
    "        \n",
    "        logits = self.fc(outputs)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_CRF_NER(nn.Module):\n",
    "    def __init__(self, vocab_size, tag_size, embedding_dim, hidden_dim, num_layers, dropout, pretrained_embeddings=None):\n",
    "        super(BiLSTM_CRF_NER, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding.weight = nn.Parameter(pretrained_embeddings)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim // 2,  \n",
    "                           num_layers=num_layers, \n",
    "                           bidirectional=True,\n",
    "                           batch_first=True,\n",
    "                           dropout=dropout if num_layers > 1 else 0)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, tag_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.transitions = nn.Parameter(torch.randn(tag_size, tag_size))\n",
    "\n",
    "        self.start_transitions = nn.Parameter(torch.randn(tag_size))\n",
    "        self.end_transitions = nn.Parameter(torch.randn(tag_size))\n",
    "        \n",
    "    def _forward_alg(self, emissions, mask):\n",
    "        batch_size, seq_length, tag_size = emissions.size()\n",
    "        \n",
    "        score = self.start_transitions + emissions[:, 0]\n",
    "        \n",
    "        for i in range(1, seq_length):\n",
    "            broadcast_score = score.unsqueeze(2)\n",
    "            broadcast_emissions = emissions[:, i].unsqueeze(1)\n",
    "            \n",
    "            next_score = broadcast_score + self.transitions + broadcast_emissions\n",
    "            \n",
    "            next_score = torch.logsumexp(next_score, dim=1)\n",
    "            \n",
    "            score = torch.where(mask[:, i].unsqueeze(1), next_score, score)\n",
    "        \n",
    "        score = score + self.end_transitions\n",
    "        \n",
    "        # 对所有可能的标签序列求和: (batch_size,)\n",
    "        return torch.logsumexp(score, dim=1)\n",
    "    \n",
    "    def _score_sentence(self, emissions, tags, mask):\n",
    "        \"\"\"计算给定标签序列的得分\"\"\"\n",
    "        batch_size, seq_length, tag_size = emissions.size()\n",
    "        \n",
    "        # 初始得分\n",
    "        score = self.start_transitions[tags[:, 0]]\n",
    "        score += emissions[torch.arange(batch_size), 0, tags[:, 0]]\n",
    "        \n",
    "        for i in range(1, seq_length):\n",
    "            # 只更新mask为1的位置\n",
    "            valid_scores = emissions[torch.arange(batch_size), i, tags[:, i]]\n",
    "            valid_scores += self.transitions[tags[:, i-1], tags[:, i]]\n",
    "            score += valid_scores * mask[:, i]\n",
    "        \n",
    "        # 添加结束转移得分\n",
    "        last_tag_indices = mask.sum(1).long() - 1\n",
    "        last_tags = tags[torch.arange(batch_size), last_tag_indices]\n",
    "        score += self.end_transitions[last_tags]\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def _viterbi_decode(self, emissions, mask):\n",
    "        \"\"\"使用Viterbi算法解码，寻找最优标签序列\"\"\"\n",
    "        batch_size, seq_length, tag_size = emissions.size()\n",
    "        \n",
    "        # 初始得分和反向指针\n",
    "        score = self.start_transitions + emissions[:, 0]\n",
    "        history = []\n",
    "        \n",
    "        for i in range(1, seq_length):\n",
    "            # (batch_size, tag_size, tag_size)\n",
    "            broadcast_score = score.unsqueeze(2)\n",
    "            broadcast_emission = emissions[:, i].unsqueeze(1)\n",
    "            \n",
    "            # (batch_size, tag_size, tag_size)\n",
    "            next_score = broadcast_score + self.transitions + broadcast_emission\n",
    "            \n",
    "            # 找到每一列的最大值和对应的索引\n",
    "            next_score, indices = next_score.max(dim=1)\n",
    "            \n",
    "            # 只更新mask为1的位置\n",
    "            score = torch.where(mask[:, i].unsqueeze(1), next_score, score)\n",
    "            history.append(indices)\n",
    "        \n",
    "        # 添加结束转移得分\n",
    "        score += self.end_transitions\n",
    "        \n",
    "        # 找到最终的最高分及其对应的最后一个标签\n",
    "        best_score, best_tag = score.max(dim=1)\n",
    "        \n",
    "        # 反向追踪最优路径\n",
    "        best_path = torch.zeros(batch_size, seq_length, dtype=torch.long, device=emissions.device)\n",
    "        best_path[:, -1] = best_tag\n",
    "        \n",
    "        for i in range(len(history) - 1, -1, -1):\n",
    "            best_tag = history[i].gather(1, best_tag.unsqueeze(1)).squeeze(1)\n",
    "            best_path[:, i] = best_tag\n",
    "        \n",
    "        return best_path, best_score\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        batch_size, max_len = x.size()\n",
    "        \n",
    "        # 创建mask\n",
    "        mask = torch.zeros(batch_size, max_len, dtype=torch.bool, device=x.device)\n",
    "        for i, length in enumerate(lengths):\n",
    "            mask[i, :length] = 1\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        \n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths.cpu(), batch_first=True)\n",
    "        outputs, _ = self.lstm(packed)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "        \n",
    "        outputs = self.dropout(outputs)\n",
    "        emissions = self.fc(outputs)\n",
    "        \n",
    "        return emissions\n",
    "    \n",
    "    def neg_log_likelihood(self, x, lengths, tags):\n",
    "        batch_size, max_len = x.size()\n",
    "        mask = torch.zeros(batch_size, max_len, dtype=torch.bool, device=x.device)\n",
    "        for i, length in enumerate(lengths):\n",
    "            mask[i, :length] = 1\n",
    "        \n",
    "        emissions = self.forward(x, lengths)\n",
    "        \n",
    "        log_Z = self._forward_alg(emissions, mask)\n",
    "        gold_score = self._score_sentence(emissions, tags, mask)\n",
    "        \n",
    "        return log_Z - gold_score\n",
    "    \n",
    "    def decode(self, x, lengths):\n",
    "        batch_size, max_len = x.size()\n",
    "        mask = torch.zeros(batch_size, max_len, dtype=torch.bool, device=x.device)\n",
    "        for i, length in enumerate(lengths):\n",
    "            mask[i, :length] = 1\n",
    "        \n",
    "        emissions = self.forward(x, lengths)\n",
    "        \n",
    "        return self._viterbi_decode(emissions, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_decode(emissions, transitions, beam_width=5):\n",
    "    \n",
    "    seq_len, tag_size = emissions.shape\n",
    "    log_probs = torch.log_softmax(emissions, dim=1)\n",
    "    \n",
    "    top_k_probs, top_k_indices = torch.topk(log_probs[0], k=min(beam_width, tag_size))\n",
    "    beam_paths = [[idx.item()] for idx in top_k_indices]\n",
    "    path_scores = top_k_probs.tolist()\n",
    "    \n",
    "    for t in range(1, seq_len):\n",
    "        new_candidates = []\n",
    "        \n",
    "        for i, path in enumerate(beam_paths):\n",
    "            path_score = path_scores[i]\n",
    "            last_tag = path[-1]\n",
    "            \n",
    "            for next_tag in range(tag_size):\n",
    "                emit_score = log_probs[t][next_tag].item()\n",
    "                trans_score = transitions[last_tag][next_tag].item()\n",
    "                \n",
    "                new_score = path_score + trans_score + emit_score\n",
    "                new_path = path + [next_tag]\n",
    "                new_candidates.append((new_score, new_path))\n",
    "        \n",
    "        new_candidates.sort(key=lambda x: x[0], reverse=True)\n",
    "        beam_paths = [cand[1] for cand in new_candidates[:beam_width]]\n",
    "        path_scores = [cand[0] for cand in new_candidates[:beam_width]]\n",
    "    \n",
    "    return torch.tensor(beam_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for sentences, tags, lengths in tqdm(train_loader, desc=\"训练\"):\n",
    "        sentences = sentences.to(device)\n",
    "        tags = tags.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(sentences, lengths)\n",
    "        \n",
    "        loss = 0\n",
    "        for i in range(logits.size(0)):\n",
    "            loss += criterion(logits[i, :lengths[i]], tags[i, :lengths[i]])\n",
    "        loss /= logits.size(0)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_crf(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for sentences, tags, lengths in tqdm(train_loader, desc=\"训练CRF\"):\n",
    "        sentences = sentences.to(device)\n",
    "        tags = tags.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = model.neg_log_likelihood(sentences, lengths, tags)\n",
    "        loss = loss.mean()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, tag_to_idx, idx_to_tag, metrics_handler, device):\n",
    "    model.eval()\n",
    "    metrics_handler = MetricsHandler(classes=list(tag_to_idx.keys()))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sentences, tags, lengths in tqdm(data_loader, desc=\"Evaluate with Greedy\"):\n",
    "            sentences = sentences.to(device)\n",
    "            tags = tags.to(device)\n",
    "\n",
    "            logits = model(sentences, lengths)\n",
    "\n",
    "            for i in range(logits.size(0)):\n",
    "                length = lengths[i]\n",
    "                logits_i = logits[i, :length]\n",
    "                tags_i = tags[i, :length]\n",
    "                \n",
    "                # 贪心\n",
    "                _, predicted = torch.max(logits_i, dim=1)\n",
    "                \n",
    "                pred_tags = [idx_to_tag[idx.item()] for idx in predicted]\n",
    "                true_tags = [idx_to_tag[idx.item()] for idx in tags_i]\n",
    "                \n",
    "                metrics_handler.update(pred_tags, true_tags)\n",
    "    \n",
    "    metrics_handler.collect()\n",
    "    metrics = metrics_handler.get_metrics()\n",
    "    \n",
    "    f1_scores = metrics[\"F1-score\"]\n",
    "    latest_f1 = f1_scores[-1] if f1_scores else 0.0\n",
    "    \n",
    "    return {\"f1\": latest_f1, \"metrics\": metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 添加CRF模型的评估函数\n",
    "\n",
    "def evaluate_crf(model, data_loader, tag_to_idx, idx_to_tag, metrics_handler, device):\n",
    "    model.eval()    \n",
    "    metrics_handler = MetricsHandler(classes=list(tag_to_idx.keys()))\n",
    "    with torch.no_grad():\n",
    "        for sentences, tags, lengths in tqdm(data_loader, desc=\"评估CRF\"):\n",
    "            sentences = sentences.to(device)\n",
    "            tags = tags.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            \n",
    "            \n",
    "            best_paths, _ = model.decode(sentences, lengths)\n",
    "            \n",
    "            for i in range(best_paths.size(0)):\n",
    "                length = lengths[i].item()\n",
    "                predicted = best_paths[i, :length]\n",
    "                tags_i = tags[i, :length]\n",
    "                \n",
    "                pred_tags = [idx_to_tag[idx.item()] for idx in predicted]\n",
    "                true_tags = [idx_to_tag[idx.item()] for idx in tags_i]\n",
    "                \n",
    "                metrics_handler.update(pred_tags, true_tags)\n",
    "    \n",
    "    metrics_handler.collect()\n",
    "    metrics = metrics_handler.get_metrics()\n",
    "    \n",
    "    f1_scores = metrics[\"F1-score\"]\n",
    "    latest_f1 = f1_scores[-1] if f1_scores else 0.0\n",
    "    \n",
    "    return {\"f1\": latest_f1, \"metrics\": metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_with_beam_search(model, data_loader, tag_to_idx, idx_to_tag, metrics_handler, device, use_beam_search=True, beam_width=5):\n",
    "    model.eval()\n",
    "    metrics_handler = MetricsHandler(classes=list(tag_to_idx.keys()))\n",
    "    with torch.no_grad():\n",
    "        for sentences, tags, lengths in tqdm(data_loader, desc=\"Evaluate with Beam\" ):\n",
    "            sentences = sentences.to(device)\n",
    "            tags = tags.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            emissions = model(sentences, lengths)\n",
    "            \n",
    "            \n",
    "            transitions = model.transitions\n",
    "           \n",
    "\n",
    "            for i in range(emissions.size(0)):\n",
    "                length = lengths[i].item()\n",
    "                emissions_i = emissions[i, :length]\n",
    "                tags_i = tags[i, :length]\n",
    "                \n",
    "                if use_beam_search and hasattr(model, 'transitions'):\n",
    "                    # 使用波束搜索\n",
    "                    predicted = beam_search_decode(\n",
    "                        emissions_i, \n",
    "                        transitions, \n",
    "                        beam_width\n",
    "                    )\n",
    "                else:\n",
    "                    # 贪婪搜索\n",
    "                    _, predicted = torch.max(emissions_i, dim=1)\n",
    "                \n",
    "                pred_tags = [idx_to_tag[idx.item()] for idx in predicted]\n",
    "                true_tags = [idx_to_tag[idx.item()] for idx in tags_i]\n",
    "                \n",
    "                metrics_handler.update(pred_tags, true_tags)\n",
    "    \n",
    "    metrics_handler.collect()\n",
    "    metrics = metrics_handler.get_metrics()\n",
    "    \n",
    "    f1_scores = metrics[\"F1-score\"]\n",
    "    latest_f1 = f1_scores[-1] if f1_scores else 0.0\n",
    "    \n",
    "    return {\"f1\": latest_f1, \"metrics\": metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET SIZE: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "加载GloVe词向量: 400000it [00:02, 161256.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载了 18415/21011 个词的预训练词向量\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import get_tag_indices_from_scores\n",
    "from metrics import MetricsHandler\n",
    "\n",
    "labels_str = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\n",
    "labels_int = list(range(len(labels_str)))\n",
    "train_metrics = MetricsHandler(labels_int)\n",
    "\n",
    "train_sentences, train_tags = load_data(os.path.join(DATA_DIR, 'train.txt'))\n",
    "dev_sentences, dev_tags = load_data(os.path.join(DATA_DIR, 'dev.txt'))\n",
    "test_sentences, test_tags = load_data(os.path.join(DATA_DIR, 'test.txt'))\n",
    "\n",
    "word_to_idx, tag_to_idx = build_vocab(train_sentences, train_tags)\n",
    "idx_to_tag = {idx: tag for tag, idx in tag_to_idx.items()}\n",
    "\n",
    "TAGSET_SIZE = len(tag_to_idx)\n",
    "\n",
    "print(f\"TARGET SIZE: {TAGSET_SIZE}\")\n",
    "\n",
    "pretrained_embeddings = load_glove_embeddings(GLOVE_PATH, word_to_idx, EMBEDDING_DIM)\n",
    "\n",
    "train_dataset = NERDataset(train_sentences, train_tags, word_to_idx, tag_to_idx)\n",
    "dev_dataset = NERDataset(dev_sentences, dev_tags, word_to_idx, tag_to_idx)\n",
    "test_dataset = NERDataset(test_sentences, test_tags, word_to_idx, tag_to_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM_NER(\n",
    "    vocab_size=len(word_to_idx),\n",
    "    tag_size=len(tag_to_idx),\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    pretrained_embeddings=pretrained_embeddings\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tag_to_idx['<PAD>'])\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics_handler = MetricsHandler(classes=list(range(TAGSET_SIZE)))\n",
    "metrics_handler_crf = MetricsHandler(classes=list(range(TAGSET_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It has model checkpoint, loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_329333/3209027670.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('bilstm_ner_model.pt')\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('bilstm_ner_model.pt'):\n",
    "    print(\"It has model checkpoint, loading...\")\n",
    "    checkpoint = torch.load('bilstm_ner_model.pt')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    word_to_idx = checkpoint['word_to_idx']\n",
    "    tag_to_idx = checkpoint['tag_to_idx']\n",
    "    idx_to_tag = checkpoint['idx_to_tag']\n",
    "else:\n",
    "    print(\"Start_training...\")\n",
    "    train_losses = []\n",
    "    dev_f1_scores = []\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        dev_metrics = evaluate(model, dev_loader, tag_to_idx, idx_to_tag, metrics_handler, device)\n",
    "        dev_f1 = dev_metrics['f1']\n",
    "        dev_f1_scores.append(dev_f1)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {train_loss:.4f}, Dev set F1: {dev_f1:.4f}\")\n",
    "\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'word_to_idx': word_to_idx,\n",
    "        'tag_to_idx': tag_to_idx,\n",
    "        'idx_to_tag': idx_to_tag,\n",
    "        'hyperparams': {\n",
    "            'embedding_dim': EMBEDDING_DIM,\n",
    "            'hidden_dim': HIDDEN_DIM,\n",
    "            'num_layers': NUM_LAYERS,\n",
    "            'dropout': DROPOUT\n",
    "        }\n",
    "    }, 'bilstm_ner_model.pt')\n",
    "    print(\"BiLSTM model trained and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 添加代码训练CRF模型并进行比较\n",
    "\n",
    "# 创建一个CRF模型\n",
    "crf_model = BiLSTM_CRF_NER(\n",
    "    vocab_size=len(word_to_idx),\n",
    "    tag_size=len(tag_to_idx),\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    pretrained_embeddings=pretrained_embeddings\n",
    ").to(device)\n",
    "\n",
    "crf_optimizer = optim.Adam(crf_model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training CRF model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练CRF: 100%|██████████| 110/110 [00:13<00:00,  8.11it/s]\n",
      "评估CRF: 100%|██████████| 26/26 [00:02<00:00, 10.93it/s]\n",
      "/home/stu_12310401/nlp/SUSTech-NLP25/Ass4/metrics.py:5: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return x[1, 1]/(x[1, 1] + x[0, 1])\n",
      "/home/stu_12310401/nlp/SUSTech-NLP25/Ass4/metrics.py:9: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return x[1, 1] / (x[1, 0] + x[1, 1])\n",
      "/home/stu_12310401/nlp/SUSTech-NLP25/Ass4/metrics.py:15: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return ((1 + beta**2)*precision*recall)/(beta**2 * precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 11.5426, Dev set F1: 0.5564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练CRF: 100%|██████████| 110/110 [00:12<00:00,  9.15it/s]\n",
      "评估CRF: 100%|██████████| 26/26 [00:02<00:00, 11.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 5.2235, Dev set F1: 0.6394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练CRF: 100%|██████████| 110/110 [00:12<00:00,  8.74it/s]\n",
      "评估CRF: 100%|██████████| 26/26 [00:02<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 3.4265, Dev set F1: 0.7305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练CRF: 100%|██████████| 110/110 [00:11<00:00,  9.18it/s]\n",
      "评估CRF: 100%|██████████| 26/26 [00:02<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 2.6634, Dev set F1: 0.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练CRF: 100%|██████████| 110/110 [00:11<00:00,  9.20it/s]\n",
      "评估CRF: 100%|██████████| 26/26 [00:02<00:00, 10.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 2.2818, Dev set F1: 0.8028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练CRF: 100%|██████████| 110/110 [00:11<00:00,  9.19it/s]\n",
      "评估CRF: 100%|██████████| 26/26 [00:02<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 1.9735, Dev set F1: 0.8025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练CRF: 100%|██████████| 110/110 [00:11<00:00,  9.19it/s]\n",
      "评估CRF: 100%|██████████| 26/26 [00:02<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 1.7476, Dev set F1: 0.8202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练CRF: 100%|██████████| 110/110 [00:11<00:00,  9.21it/s]\n",
      "评估CRF: 100%|██████████| 26/26 [00:02<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 1.5591, Dev set F1: 0.8295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练CRF: 100%|██████████| 110/110 [00:11<00:00,  9.20it/s]\n",
      "评估CRF: 100%|██████████| 26/26 [00:02<00:00, 11.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 1.4060, Dev set F1: 0.8397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练CRF: 100%|██████████| 110/110 [00:11<00:00,  9.57it/s]\n",
      "评估CRF: 100%|██████████| 26/26 [00:02<00:00, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 1.2792, Dev set F1: 0.8453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('bilstm_crf_ner_model.pt'):\n",
    "    print(\"It has CRF model checkpoint, loading...\")\n",
    "    checkpoint = torch.load('bilstm_crf_ner_model.pt')\n",
    "    crf_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    word_to_idx = checkpoint['word_to_idx']\n",
    "    tag_to_idx = checkpoint['tag_to_idx']\n",
    "    idx_to_tag = checkpoint['idx_to_tag']\n",
    "else:\n",
    "    print(\"Start training CRF model...\")\n",
    "    crf_train_losses = []\n",
    "    crf_dev_f1_scores = []\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss = train_crf(crf_model, train_loader, crf_optimizer, device)\n",
    "        crf_train_losses.append(train_loss)\n",
    "        \n",
    "        dev_metrics = evaluate_crf(crf_model, dev_loader, tag_to_idx, idx_to_tag, metrics_handler_crf, device)\n",
    "        dev_f1 = dev_metrics['f1']\n",
    "        crf_dev_f1_scores.append(dev_f1)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {train_loss:.4f}, Dev set F1: {dev_f1:.4f}\")\n",
    "\n",
    "\n",
    "    torch.save({\n",
    "        'model_state_dict': crf_model.state_dict(),\n",
    "        'word_to_idx': word_to_idx,\n",
    "        'tag_to_idx': tag_to_idx,\n",
    "        'idx_to_tag': idx_to_tag,\n",
    "        'hyperparams': {\n",
    "            'embedding_dim': EMBEDDING_DIM,\n",
    "            'hidden_dim': HIDDEN_DIM,\n",
    "            'num_layers': NUM_LAYERS,\n",
    "            'dropout': DROPOUT\n",
    "        }\n",
    "    }, 'bilstm_crf_ner_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compare Decode method：\n",
      "--------------------------------------------------------------------------------\n",
      "Model + Decode method          Dev set F1      Test set F1    \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate with Greedy: 100%|██████████| 26/26 [00:02<00:00, 12.61it/s]\n",
      "Evaluate with Greedy: 100%|██████████| 27/27 [00:01<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM + Greedy search         0.8374          0.7860         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate with Beam: 100%|██████████| 26/26 [00:49<00:00,  1.91s/it]\n",
      "Evaluate with Beam: 100%|██████████| 27/27 [00:44<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM-CRF + Beam search (width=3) 0.8437          0.7952         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate with Beam: 100%|██████████| 26/26 [01:22<00:00,  3.16s/it]\n",
      "Evaluate with Beam: 100%|██████████| 27/27 [01:13<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM-CRF + Beam search (width=5) 0.8443          0.7960         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate with Beam: 100%|██████████| 26/26 [02:39<00:00,  6.15s/it]\n",
      "Evaluate with Beam: 100%|██████████| 27/27 [02:22<00:00,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM-CRF + Beam search (width=10) 0.8445          0.7952         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_handler = MetricsHandler(classes=list(range(TAGSET_SIZE)))\n",
    "metrics_handler_crf = MetricsHandler(classes=list(range(TAGSET_SIZE)))\n",
    "beam_widths = [3,5,10]\n",
    "\n",
    "print(\"\\nCompare Decode method：\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Model + Decode method':<30} {'Dev set F1':<15} {'Test set F1':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "greedy_dev_metrics = evaluate(model, dev_loader, tag_to_idx, idx_to_tag, metrics_handler, device)\n",
    "greedy_test_metrics = evaluate(model, test_loader, tag_to_idx, idx_to_tag, metrics_handler, device)\n",
    "print(f\"{'BiLSTM + Greedy search':<30} {greedy_dev_metrics['f1']:<15.4f} {greedy_test_metrics['f1']:<15.4f}\")\n",
    "\n",
    "for beam_width in beam_widths:\n",
    "    crf_beam_dev_metrics = evaluate_with_beam_search(crf_model, dev_loader, tag_to_idx, idx_to_tag, metrics_handler_crf, device, use_beam_search=True, beam_width=beam_width)\n",
    "    crf_beam_test_metrics = evaluate_with_beam_search(crf_model, test_loader, tag_to_idx, idx_to_tag, metrics_handler_crf, device, use_beam_search=True, beam_width=beam_width)\n",
    "    print(f\"{'BiLSTM-CRF + Beam search (width=' + str(beam_width) + ')':<30} {crf_beam_dev_metrics['f1']:<15.4f} {crf_beam_test_metrics['f1']:<15.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Other Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wzh-py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
